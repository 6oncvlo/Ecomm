{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "- Import the required libraries and helper functions\n",
    "- Load configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "import yaml\n",
    "import itertools\n",
    "import mlflow\n",
    "from src.data.data_loader import load_data, prepare_data, load_queries\n",
    "from src.data.data_preparation import feature_selection\n",
    "from src.models.clustering import AnomalyDetection\n",
    "from src.models.utils import log_artifact\n",
    "from src.models.explainability import ModelExplainability\n",
    "from src.visuals.plots import kde_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading and Feature Engineering**\n",
    "- Load raw data using specified paths from the configuration file and preprocesses it for modeling\n",
    "- Extracts visitor-level features and applies a feature selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare raw data\n",
    "data = load_data(data_paths = config['data_loader'])\n",
    "data = prepare_data(data = data, config = config['data_preparation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visitor level features and perform feature selection\n",
    "data_features = load_queries(data_paths= config['features'], data= data)\n",
    "features_visitor = data_features['visitor']\n",
    "config['model']['anomaly_detection']['features'] = feature_selection(dataframe = features_visitor)\n",
    "del data, data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evalutation and Explainability**\n",
    "- Fit the Isolation Forest model using grid search over multiple parameter combinations\n",
    "- Leverages MLflow for tracking runs, logging metrics, and storing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare parameter combinations\n",
    "params_space = config['model']['anomaly_detection']['isolation_forest']['params']\n",
    "param_combinations = [\n",
    "    dict(zip(params_space.keys(), combo)) for combo in itertools.product(*params_space.values())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up MLflow tracking\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(experiment_name='Anomaly_Detection')\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# open a run for Isolation Forest algorithm\n",
    "with mlflow.start_run(run_name='Isolation_Forest'):\n",
    "    for params in param_combinations:\n",
    "        # select isolation forest algo and respective params\n",
    "        if_Model = AnomalyDetection(method='isolation_forest', **params)\n",
    "\n",
    "        # each param combination is logged under a new nested run\n",
    "        with mlflow.start_run(nested=True):\n",
    "            # train algorithm and infer prediction label and its score\n",
    "            if_Model.fit(features_visitor[config['model']['anomaly_detection']['features']])\n",
    "            features_visitor['anomaly_label'] = if_Model.predict(features_visitor[config['model']['anomaly_detection']['features']])\n",
    "            features_visitor['anomaly_score'] = if_Model.scoring(features_visitor[config['model']['anomaly_detection']['features']])\n",
    "\n",
    "            # logging config, params and model\n",
    "            mlflow.log_dict(dictionary=config, artifact_file=\"config.yml\")\n",
    "            mlflow.log_params(params=params)\n",
    "            signature = mlflow.models.infer_signature(\n",
    "                model_input = features_visitor[config['model']['anomaly_detection']['features']]\n",
    "                , model_output = features_visitor['anomaly_label']\n",
    "                )\n",
    "            mlflow.sklearn.log_model(sk_model=if_Model.model, artifact_path='model_instance', signature=signature)\n",
    "\n",
    "            # set model explainability for the model instance\n",
    "            if_ModelExplainability = ModelExplainability(model=if_Model, data=features_visitor[config['model']['anomaly_detection']['features']])\n",
    "            # temporally locally save visuals to be logged as artifacts\n",
    "            kde_group(features_visitor, measure='anomaly_score', column_group='anomaly_label', xlabel='Anomaly Score', save_path='kde_anomaly_score')\n",
    "            if_ModelExplainability.shap_values.plot(method='global', save_path='shap_feature_importance')\n",
    "            if_ModelExplainability.shap_values.plot(method='instance', save_path='shap_example_instance')\n",
    "            if_ModelExplainability.tree_estimator(save_path='example_estimator')\n",
    "            # logging artifacts\n",
    "            artifacts = [\n",
    "                ('datasets', features_visitor, 'visitor_features', None)\n",
    "                , ('visuals', None, None, 'kde_anomaly_score')\n",
    "                , ('stats', features_visitor.groupby(by=['anomaly_label'])['anomaly_score'].describe().round(2).reset_index(), 'anomaly_score_stats', None)\n",
    "                , ('feature_importance', if_ModelExplainability.feature_importance(), 'naive_feature_importance', None)\n",
    "                , ('feature_importance', if_ModelExplainability.shap_values.importance_values(), 'shap_feature_importance', None)\n",
    "                , ('visuals', None, None, 'shap_feature_importance')\n",
    "                , ('visuals', None, None, 'shap_example_instance')\n",
    "                , ('visuals', None, None, 'example_estimator')\n",
    "                , ('stats',\n",
    "                   features_visitor.groupby(by=['anomaly_label']).agg({\n",
    "                       col: ['min', 'median', 'max', 'std'] for col in if_ModelExplainability.feature_importance().iloc[:10,].index.to_list()\n",
    "                       }).round(2).T, 'naive_top10_features_stats', None)\n",
    "                ]\n",
    "            for artifact_path, df, df_name, image_name in artifacts:\n",
    "                log_artifact(artifact_path, df, df_name, image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Explainability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 1 or 2 features\n",
    "#kde_group(dataframe = features_visitor, measure = 'num_views', column_group='anomaly_label', xlabel='num_views')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

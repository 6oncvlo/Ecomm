{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# add the root of the project to the Python path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "from src.data.data_loader import load_data, prepare_data\n",
    "from src.data.features import visitor_features\n",
    "from src.models.clustering import AnomalyDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config/config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader=yaml.SafeLoader)\n",
    "\n",
    "# load and prepare data\n",
    "data = load_data(data_paths = config['data_loader'])\n",
    "data = prepare_data(data = data, config = config['data_preparation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_visitor = visitor_features(data = data, config = config['data_preparation'])\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'n_estimators': 100\n",
    "    , 'max_samples': 'auto'\n",
    "    , 'contamination': 'auto'\n",
    "    , 'max_features': 1.0\n",
    "    , 'bootstrap': False\n",
    "    , 'n_jobs': -1, 'random_state': 42, 'verbose': 0\n",
    "    }\n",
    "model = AnomalyDetection(method='isolation_forest', **params)\n",
    "\n",
    "# train algorithm\n",
    "model_cols = features_visitor.columns\n",
    "model.fit(features_visitor[model_cols])\n",
    "# inference phase with prediction label and its score\n",
    "features_visitor['anomaly_label'], features_visitor['anomaly_score'] = model.predict(features_visitor), model.get_scores(features_visitor)\n",
    "\n",
    "# find the number of anomalies and normal points here points classified -1 are anomalous\n",
    "print(features_visitor['anomaly_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visuals.plots import kde_group\n",
    "\n",
    "kde_group(dataframe = features_visitor, measure = 'anomaly_score', column_group='anomaly_label', xlabel='Anomaly Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_visitor.groupby(by=['anomaly']).agg({\n",
    "    'min_view_delta': ['min', 'mean', 'max']\n",
    "    , 'mean_view_delta': ['min', 'mean', 'max']\n",
    "    , 'max_view_delta': ['min', 'mean', 'max']\n",
    "    #, 'numevents_1824h': ['min', 'mean', 'max']\n",
    "    #, 'numevents_0006h': ['min', 'mean', 'max']\n",
    "    , 'total_events': ['min', 'mean', 'max']\n",
    "    , 'num_views': ['min', 'mean', 'max']\n",
    "    , 'repetitive_action_count': ['min', 'mean', 'max']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize array to store feature contributions\n",
    "feature_importances = np.zeros(features_visitor[model_cols].shape[1])\n",
    "\n",
    "# Access 'estimators_' safely\n",
    "estimators = model.get_model_attribute(\"estimators_\")\n",
    "for tree in estimators:\n",
    "    tree_features = tree.tree_.feature\n",
    "    # Count how many times each feature is used across all splits in this tree\n",
    "    for feature in range(features_visitor[model_cols].shape[1]):\n",
    "        # Sum path lengths for nodes where this feature is used to split\n",
    "        feature_importances[feature] += np.sum(tree_features == feature)\n",
    "\n",
    "# Normalize to get relative feature contributions\n",
    "feature_importances /= feature_importances.sum()\n",
    "feature_contributions = pd.Series(feature_importances, index=features_visitor[model_cols].columns)\n",
    "display(\"Feature Contributions to Anomaly Scores:\",\n",
    "        pd.DataFrame(feature_contributions, columns=['weight']).sort_values(by='weight', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# SHAP Explanation for Tree-based Models\n",
    "explainer = shap.TreeExplainer(model.model)\n",
    "\n",
    "# Calculate SHAP values for each instance\n",
    "shap_values = explainer.shap_values(features_visitor[model_cols])\n",
    "\n",
    "# SHAP values give us a per-instance, per-feature contribution to the anomaly score\n",
    "# For a specific instance, view SHAP values and plot them\n",
    "instance_index = 0  # Choose an index to explain\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[instance_index], features_visitor[model_cols].iloc[instance_index])\n",
    "\n",
    "# Global summary plot to view the overall feature importance for anomaly detection\n",
    "shap.summary_plot(shap_values, features_visitor[model_cols], plot_type=\"bar\")\n",
    "\n",
    "# Optional: Use a SHAP dependence plot for specific features\n",
    "shap.dependence_plot(\"mean_view_delta\", shap_values, features_visitor[model_cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load libraries and config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# add the root of the project to the Python path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import yaml\n",
    "from src.data.data_loader import load_data, prepare_data\n",
    "from src.data.features import visitor_features\n",
    "from src.data.data_preparation import feature_selection\n",
    "from src.data.utils import downcast_cols, normalization\n",
    "import numpy as np\n",
    "from src.models.clustering import AnomalyDetection\n",
    "from src.models.explainability import ModelExplainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config\n",
    "with open('config/config.yml', 'r') as file:\n",
    "    config=yaml.load(file, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load visitorid features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "data = load_data(data_paths = config['data_loader'])\n",
    "data = prepare_data(data = data, config = config['data_preparation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features at visitorid level and go through feature selection process\n",
    "features_visitor = visitor_features(data = data, config = config['data_preparation'], drop_bouncers=True)\n",
    "features_visitor = feature_selection(dataframe = features_visitor)\n",
    "\n",
    "# data normalization\n",
    "features_visitor = normalization(dataframe = features_visitor, method = 'min_max')\n",
    "features_visitor = downcast_cols(dataframe = features_visitor)\n",
    "features_visitor = np.array(features_visitor)\n",
    "\n",
    "del data, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visuals.plots import k_distance\n",
    "\n",
    "k_distance(data=features_visitor, zoom_last_n_points=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit DBSCAN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select isolation forest algo and respective params\n",
    "dbscan_params = config['model']['dbscan']['params']\n",
    "dbscan_params['eps'], dbscan_params['min_samples'] = 1, 2*features_visitor.shape[1]\n",
    "dbscan_Model = AnomalyDetection(method='dbscan', **dbscan_params)\n",
    "\n",
    "# train algorithm and infer prediction label and its score\n",
    "dbscan_Model.fit(features_visitor)\n",
    "#features_visitor['anomaly_label'] = dbscan_Model.predict(features_visitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_visitor.groupby(by=['anomaly_label']).agg({\n",
    "    col: ['min', 'mean', 'max'] for col in ['min_view_delta', 'mean_view_delta', 'max_view_delta', 'repetitive_action_count']\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
